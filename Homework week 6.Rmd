---
title: "Week 6 Homework"
author: "Brandon Güell"
date: "10/19/2017"
output: html_document
---

1: Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines

```{r}
z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = c("two.sided", "less", "greater"), conf.level =0.95)
{
  
  OK <- complete.cases(p1, n1, p0)
    p1 <- p1[OK]
    n1 <- n1[OK]
    p0 <- p0[OK]
 
    
    if (n1*p1 < 5)
	warning("assumption is not met")
    if (n1 * (1-p1) < 5)
  warning("assumption is not met")
    
    
    if (is.null(c(p2,n2))) {
	  z <- (p1-p0)/sqrt((p0 * (1-p0)/n1))
    lower <- p1 - qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
    upper <- p1 + qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
    ci <- c(lower, upper)
    
        if (alternative == "less") {
            p <- pnorm(z, lower.tail = TRUE)
        }
        if (alternative == "greater") {
            p <- pnorm(z, lower.tail = FALSE)
        }
        if (alternative == "two.sided") {
            if (z > 0) 
                {
                  p <- 2 * pnorm(z, lower.tail = FALSE)
                } 
            if (z < 0) 
                {
                  p <- 2 * pnorm(z, lower.tail = TRUE)
                }  

        }
    }
    
    #SECOND PART STARTS HERE FOR TWO-SAMPLE
   else  {
     pstar= p1+p2
     pci= p2-p1
     ntot= n1 + n2
	  z <- (p2 - p1)/sqrt((pstar * (1 - pstar)) * (1/n1) + 1/n2)
	  
    lower <- pci - qnorm(0.975) * sqrt(pci * (1 - pci)/ntot)
    upper <- pci + qnorm(0.975) * sqrt(pci * (1 - pci)/ntot)
    ci <- c(lower, upper)
    
        if (alternative == "less") {
            p <- pnorm(z, lower.tail = TRUE)
        }
        if (alternative == "greater") {
            p <- pnorm(z, lower.tail = FALSE)
        }
        if (alternative == "two.sided") {
            if (z > 0) 
                {
                  p <- 2 * pnorm(z, lower.tail = FALSE)
                } 
            if (z < 0) 
                {
                  p <- 2 * pnorm(z, lower.tail = TRUE)
                }  

        }
    }
    
	  
	  
  spitout <- list(statistic = z,
		 p.value = p,
		 conf.int = ci,
		 alternative = alternative)
  
    return(spitout)
  }
```




2: The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both  longevity~brain size and  log(longevity)~log(brain size).

First for longevity~brain size

```{r}
library(curl)
library(ggplot2)

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

#first for logevity~brain size
plot(data=d, MaxLongevity_m~Brain_Size_Species_Mean)

m= lm(data=d, MaxLongevity_m~Brain_Size_Species_Mean)
m
#Here B1== 1.218 and B0== 248.952
summary(m)

ci = confint(m, level = 0.90)
ci
# ci ==  1.035571 & 1.40041

g= ggplot(data = d, aes(x=log(Brain_Size_Species_Mean), y=MaxLongevity_m)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) + annotate("text", x = 4, y = 25, label = "y = 1.218x + 248.952")
g
```



Here I begin to write code for the CI and Prediction Intervals:
```{r}
v = seq(from = 0, to = 500, by = 1)
m = lm(data=d, MaxLongevity_m~Brain_Size_Species_Mean)
ci = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.90)
pi = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.90)

plot(data = d,MaxLongevity_m ~ Brain_Size_Species_Mean)
lines(x = v, y = ci[, 1], col = "black")
lines(x = v, y = ci[, 2], col = "blue")
lines(x = v, y = ci[, 3], col = "blue")
lines(x = v, y = pi[, 2], col = "red")
lines(x = v, y = pi[, 3], col = "red")

df <- data.frame(cbind(v, ci, pi))
names(df) <- c("Brain_Size_Species_Mean", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df)

g1 <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
g1 <- g1 + geom_point(alpha = 1/2)
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIfit), colour = "black", lwd = 1)
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIlwr), colour = "blue")
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIupr), colour = "blue")
g1 <- g1 + geom_line(data = df, aes(x = v, y = PIlwr), colour = "red")
g1 <- g1 + geom_line(data = df, aes(x = v, y = PIupr), colour = "red")

g1 = g1 + annotate("text", x = 350, y = 225, label = "red = 90% PI interval, blue = 90% CI interval")
g1                              

```


Here I predict the 90 percent PI for the longevity of a species whose brain weight is 800 gm. 
```{r}
ppi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction", level = 0.90)  # for a single value
ppi
```
I somewhat trust this model but not much because the r squared value is quite low at .48 which means less than 50% of the variation in max longevity is explained by brain size species mean. Also hte prediction intervals are quite large.


***************************************
***************************************
***************************************
***************************************
***************************************
***************************************
***************************************
***************************************
***************************************
#Starting it all again for the log(longevity)~log(brain size)
```{r}
library(curl)
library(ggplot2)

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

d$MaxLongevity_m=log(d$MaxLongevity_m)
d$Brain_Size_Species_Mean=log(d$Brain_Size_Species_Mean)
#first for logevity~brain size
plot(data=d, MaxLongevity_m~Brain_Size_Species_Mean)

m= lm(data=d, MaxLongevity_m~Brain_Size_Species_Mean)
m
#Here B1== 0.2341 and B0== 4.8790
summary(m)

ci = confint(m, level = 0.90)
ci
# ci == 0.2046396 & 0.2636595

g= ggplot(data = d, aes(x=Brain_Size_Species_Mean, y=MaxLongevity_m)) + geom_point() + geom_smooth(method = "lm", formula = y~x) + annotate("text", x = 4, y = 4.5, label = "y = 1.218x + 248.952") 
g

```



Here I begin to write code for the CI and Prediction Intervals:
```{r}
v = seq(from = 0, to = 7, by = 1)
m = lm(data=d, MaxLongevity_m~Brain_Size_Species_Mean)
ci = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.95)
pi = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.95)

plot(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
lines(x = v, y = ci[, 1], col = "black")
lines(x = v, y = ci[, 2], col = "blue")
lines(x = v, y = ci[, 3], col = "blue")
lines(x = v, y = pi[, 2], col = "red")
lines(x = v, y = pi[, 3], col = "red")

df <- data.frame(cbind(v, ci, pi))
names(df) <- c("Brain_Size_Species_Mean", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df)

g1 <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
g1 <- g1 + geom_point(alpha = 1/2)
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIfit), colour = "black", lwd = 1)
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIlwr), colour = "blue")
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIupr), colour = "blue")
g1 <- g1 + geom_line(data = df, aes(x = v, y = PIlwr), colour = "red")
g1 <- g1 + geom_line(data = df, aes(x = v, y = PIupr), colour = "red")

g1 = g1 + annotate("text", x = 4, y = 4, label = "red = 90% PI interval, blue = 90% CI interval")
g1

```


Here I predict the 90 percent PI for the longevity of a species whose brain weight is 800 gm. 
```{r}
ppi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction", level = 0.90)  # for a single value
ppi

```
I trust this model more because the r squared value is higher at .57 which means less than 57% of the variation in log max longevity is explained by log brain size species mean. Also the prediction intervals are much smaller